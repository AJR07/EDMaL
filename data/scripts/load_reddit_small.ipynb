{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook Details\n",
        "Notebook to generate the Reddit Small Dataset. Similar to that of the python script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TzLT6AyP-2jV",
        "outputId": "70758350-9869-46b7-f4f6-28a7e473ad38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: convokit in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (3.0.0)\n",
            "Requirement already satisfied: tqdm in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (4.66.1)\n",
            "Requirement already satisfied: nlpaug in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (1.1.11)\n",
            "Requirement already satisfied: transformers in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (4.30.2)\n",
            "Requirement already satisfied: clean-text in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (0.6.0)\n",
            "Requirement already satisfied: nltk in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (3.8.1)\n",
            "Requirement already satisfied: tensorflow in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (2.11.0)\n",
            "Requirement already satisfied: openai in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (1.3.1)\n",
            "Requirement already satisfied: spacy>=2.3.5 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from convokit) (2.3.9)\n",
            "Requirement already satisfied: dill>=0.2.9 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from convokit) (0.3.7)\n",
            "Requirement already satisfied: msgpack-numpy>=0.4.3.2 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from convokit) (0.4.8)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from convokit) (1.3.2)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from convokit) (6.0.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from convokit) (1.7.3)\n",
            "Requirement already satisfied: unidecode>=1.1.1 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from convokit) (1.3.7)\n",
            "Requirement already satisfied: pymongo>=4.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from convokit) (4.6.0)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from convokit) (3.5.3)\n",
            "Requirement already satisfied: dnspython>=1.16.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from convokit) (2.3.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from convokit) (1.0.2)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from convokit) (1.3.5)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from nlpaug) (4.7.1)\n",
            "Requirement already satisfied: requests>=2.22.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from nlpaug) (2.31.0)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from nlpaug) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: importlib-metadata in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from transformers) (6.7.0)\n",
            "Requirement already satisfied: filelock in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from transformers) (2023.10.3)\n",
            "Requirement already satisfied: emoji<2.0.0,>=1.0.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from clean-text) (1.7.0)\n",
            "Requirement already satisfied: ftfy<7.0,>=6.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from clean-text) (6.1.1)\n",
            "Requirement already satisfied: click in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from tensorflow) (2.11.2)\n",
            "Requirement already satisfied: setuptools in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from tensorflow) (65.6.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from tensorflow) (2.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from tensorflow) (1.59.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from tensorflow) (4.7.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from openai) (2.5.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from openai) (1.8.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from openai) (0.24.1)\n",
            "Requirement already satisfied: idna>=2.8 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from anyio<4,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from ftfy<7.0,>=6.0->clean-text) (0.2.12)\n",
            "Requirement already satisfied: beautifulsoup4 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from gdown>=4.0.0->nlpaug) (4.12.2)\n",
            "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from httpx<1,>=0.23.0->openai) (0.17.3)\n",
            "Requirement already satisfied: certifi in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Requirement already satisfied: fsspec in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from matplotlib>=3.0.0->convokit) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from matplotlib>=3.0.0->convokit) (4.38.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from matplotlib>=3.0.0->convokit) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from matplotlib>=3.0.0->convokit) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from matplotlib>=3.0.0->convokit) (9.5.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from matplotlib>=3.0.0->convokit) (1.4.5)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from msgpack-numpy>=0.4.3.2->convokit) (1.0.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from pandas>=0.23.4->convokit) (2023.3.post1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from pydantic<3,>=1.9.0->openai) (0.5.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.5 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from requests>=2.22.0->nlpaug) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from requests>=2.22.0->nlpaug) (2.0.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from scikit-learn>=0.20.0->convokit) (3.1.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from spacy>=2.3.5->convokit) (3.0.9)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from spacy>=2.3.5->convokit) (1.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from spacy>=2.3.5->convokit) (1.0.10)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from spacy>=2.3.5->convokit) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from spacy>=2.3.5->convokit) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from spacy>=2.3.5->convokit) (2.0.8)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from spacy>=2.3.5->convokit) (7.4.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from spacy>=2.3.5->convokit) (0.10.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from spacy>=2.3.5->convokit) (0.7.11)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.23.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.15.0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from httpcore<0.18.0,>=0.15.0->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.4.1)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /home/ajunray/anaconda3/envs/env1/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install convokit tqdm nlpaug transformers clean-text nltk tensorflow openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4v8uUIzCb5A"
      },
      "source": [
        "# Human-typed dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9uQHr_6-kdO",
        "outputId": "d72419a7-e498-4ed6-d2f4-4d30feafec95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading reddit-corpus-small to /home/ajunray/.convokit/downloads/reddit-corpus-small\n",
            "Downloading reddit-corpus-small from http://zissou.infosci.cornell.edu/convokit/datasets/subreddit-corpus/reddit-corpus-small.corpus.zip (37.9MB)... "
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_8424/973628803.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconvokit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCorpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"reddit-corpus-small\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/envs/env1/lib/python3.7/site-packages/convokit/util.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(name, verbose, data_dir, use_newest_version, use_local)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatasetURLs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0m_download_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownloadeds_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset already exists at {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/env1/lib/python3.7/site-packages/convokit/util.py\u001b[0m in \u001b[0;36m_download_helper\u001b[0;34m(dataset_path, url, verbose, name, downloadeds_path)\u001b[0m\n\u001b[1;32m    253\u001b[0m             )\n\u001b[1;32m    254\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Downloading\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"(\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\")...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;31m# post-process (extract) corpora\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/env1/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;34m\"\"\"copy data from file-like object fsrc to file-like object fdst\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/env1/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/env1/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/env1/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/env1/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/env1/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from convokit import Corpus, download\n",
        "corpus = Corpus(filename=download(\"reddit-corpus-small\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8qerWiD_PAO",
        "outputId": "122fcd9c-0612-4dcf-94bb-7a06c0f58475"
      },
      "outputs": [],
      "source": [
        "corpus.print_summary_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9nNRD3EohcF-"
      },
      "outputs": [],
      "source": [
        "def save(uttr_current, file_name):\n",
        "  with open(file_name, \"w+\") as f:\n",
        "    for utt in uttr_current:\n",
        "        f.write(str(utt) + \"\\n------\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-A4e5hk1AheV"
      },
      "outputs": [],
      "source": [
        "utterances = []\n",
        "\n",
        "for utt in corpus.iter_utterances():\n",
        "    utterances.append(utt.text)\n",
        "save(utterances, \"reddit-corpus-small.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuklCx9_Chdi"
      },
      "source": [
        "## Pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VX7fDwp1SPUo",
        "outputId": "cbfc12fe-97b8-4b45-c108-73e13916dfc4"
      },
      "outputs": [],
      "source": [
        "# use of clean-text to strip various un-needed information\n",
        "# https://pypi.org/project/clean-text/\n",
        "\n",
        "from cleantext import clean\n",
        "import tqdm\n",
        "import re\n",
        "\n",
        "emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "\n",
        "for utt_idx in tqdm.tqdm(range(len(utterances))):\n",
        "  utterances[utt_idx] = clean(utterances[utt_idx],\n",
        "      fix_unicode=True,\n",
        "      to_ascii=True,\n",
        "      lower=True,\n",
        "      no_urls=True,\n",
        "      no_emails=True,\n",
        "      no_phone_numbers=True,\n",
        "      no_currency_symbols=True,\n",
        "      replace_with_url=\"<URL>\",\n",
        "      replace_with_email=\"<EMAIL>\",\n",
        "      replace_with_phone_number=\"<PHONE>\",\n",
        "      replace_with_currency_symbol=\"<CUR>\",\n",
        "      lang=\"en\"\n",
        "  )\n",
        "  utterances[utt_idx] = emoji_pattern.sub(r'', utterances[utt_idx]) # no emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxr3WVkZCz1F",
        "outputId": "0f5e8a1f-92ef-4b2d-ed34-964739b2d69d"
      },
      "outputs": [],
      "source": [
        "# Remove utterances < 20 characters and > 300 characters\n",
        "print(len(utterances))\n",
        "utterances = [utt for utt in utterances if len(utt) >= 3000]\n",
        "print(len(utterances))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VOgm8L0CjGT",
        "outputId": "83abe143-0a15-45bc-b519-25ff0422c575"
      },
      "outputs": [],
      "source": [
        "# Remove repeated utterances\n",
        "print(len(utterances))\n",
        "utterances = list(set(utterances))\n",
        "print(len(utterances))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wjVyAqFhfT4"
      },
      "outputs": [],
      "source": [
        "save(utterances, \"post-pruned.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsQsed0NdM4D"
      },
      "source": [
        "Tokenization using nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoqcxwC9dL0-",
        "outputId": "e4448f66-ffbd-4a3c-efc5-96647d0c294c"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "tokenized_human = []\n",
        "utterances_human = utterances\n",
        "\n",
        "for utt_idx in tqdm.tqdm(range(len(utterances))):\n",
        "  tokenized_human.append(' '.join(word_tokenize(utterances[utt_idx])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWF9EXKFlJha"
      },
      "outputs": [],
      "source": [
        "save(tokenized_human, \"tokenized.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "194315\n"
          ]
        }
      ],
      "source": [
        "utterances_human = []\n",
        "with open(\"post-pruned.txt\", \"r\") as f:\n",
        "\tlines = f.readlines()\n",
        "\tlines = '\\n'.join(lines)\n",
        "\tutterances_human = lines.split('\\n------\\n')\n",
        "print(len(utterances_human))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6S02_FHEc4I1"
      },
      "source": [
        "# AI-generated dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI9tweWBsz_5"
      },
      "source": [
        "Using GPT-2 from huggingface, we generate separate sub-datasets representing:\n",
        "- Create\n",
        "- Reply\n",
        "In a 50% - 50% ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ca6LW78Dc9PF",
        "outputId": "7ca1c59d-77c5-4a5b-83ee-4683572cc56b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 8/2000 [00:09<40:07,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 14/2000 [00:23<1:06:44,  2.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▎         | 71/2000 [01:45<42:08,  1.31s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 100/2000 [02:35<1:00:33,  1.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: \n",
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 147/2000 [03:45<41:33,  1.35s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 154/2000 [03:55<36:55,  1.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 202/2000 [05:11<46:21,  1.55s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 223/2000 [05:47<55:18,  1.87s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 287/2000 [07:30<39:26,  1.38s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 289/2000 [07:34<43:44,  1.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 290/2000 [07:38<1:02:33,  2.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 320/2000 [08:22<39:54,  1.43s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 386/2000 [10:14<1:09:08,  2.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 417/2000 [11:06<33:12,  1.26s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 423/2000 [11:19<53:07,  2.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▍       | 495/2000 [13:12<38:13,  1.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 508/2000 [13:32<35:42,  1.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 519/2000 [13:48<35:56,  1.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 546/2000 [14:37<55:33,  2.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 559/2000 [14:59<32:04,  1.34s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 29%|██▊       | 573/2000 [15:26<37:56,  1.60s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 29%|██▉       | 582/2000 [15:39<37:03,  1.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 646/2000 [17:10<28:55,  1.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 666/2000 [17:41<29:00,  1.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 679/2000 [18:00<27:39,  1.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▍      | 695/2000 [18:30<42:15,  1.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 709/2000 [18:49<25:57,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 753/2000 [20:01<35:28,  1.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|███▉      | 791/2000 [21:08<34:56,  1.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████      | 816/2000 [21:58<39:09,  1.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 843/2000 [22:47<26:11,  1.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▎     | 871/2000 [23:37<42:23,  2.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 905/2000 [24:38<26:22,  1.45s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 1017/2000 [27:38<20:09,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n",
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 1048/2000 [28:44<34:31,  2.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 53%|█████▎    | 1057/2000 [28:59<22:55,  1.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▍    | 1096/2000 [29:58<19:29,  1.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 1103/2000 [30:08<23:33,  1.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 1108/2000 [30:16<21:41,  1.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|█████▌    | 1114/2000 [30:27<22:30,  1.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|█████▌    | 1121/2000 [30:44<38:23,  2.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|█████▉    | 1198/2000 [32:56<22:11,  1.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 1202/2000 [33:02<17:20,  1.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 1205/2000 [33:09<23:04,  1.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 1208/2000 [33:15<24:54,  1.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|██████▏   | 1226/2000 [33:53<29:44,  2.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|██████▏   | 1227/2000 [33:55<27:35,  2.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 1251/2000 [34:35<18:10,  1.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 1253/2000 [34:38<18:26,  1.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 1283/2000 [35:24<16:34,  1.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▍   | 1291/2000 [35:43<28:26,  2.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▍   | 1292/2000 [35:45<26:50,  2.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 1301/2000 [35:58<18:32,  1.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 1305/2000 [36:06<22:02,  1.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 1337/2000 [36:55<14:38,  1.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 1344/2000 [37:07<18:49,  1.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n",
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 1346/2000 [37:14<27:32,  2.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 1355/2000 [37:28<14:57,  1.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▍  | 1491/2000 [41:24<16:34,  1.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▌  | 1513/2000 [42:04<14:34,  1.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 1569/2000 [43:35<10:20,  1.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 79%|███████▉  | 1580/2000 [43:55<13:50,  1.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 82%|████████▏ | 1648/2000 [45:45<07:55,  1.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▍ | 1697/2000 [47:01<09:01,  1.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 1702/2000 [47:10<09:07,  1.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 88%|████████▊ | 1764/2000 [49:53<1:12:27, 18.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|████████▉ | 1796/2000 [50:52<07:11,  2.11s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 91%|█████████ | 1816/2000 [51:24<03:50,  1.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 1858/2000 [52:31<03:45,  1.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▎| 1874/2000 [52:59<03:51,  1.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▍| 1899/2000 [53:41<02:48,  1.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 1904/2000 [53:51<02:39,  1.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 1905/2000 [53:53<02:44,  1.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 1935/2000 [54:42<01:59,  1.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 1937/2000 [54:47<02:08,  2.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n",
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 1956/2000 [55:21<00:54,  1.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 1988/2000 [56:11<00:17,  1.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 1999/2000 [56:32<00:02,  2.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2000/2000 [56:35<00:00,  1.70s/it]\n"
          ]
        }
      ],
      "source": [
        "import tqdm\n",
        "import openai\n",
        "import random\n",
        "import os\n",
        "\n",
        "openai.api_key=\"API_KEY\"\n",
        "os.environ['AZURE_OPENAI_ENDPOINT']=\"API_ENDPOINT\"\n",
        "openai.api_type = \"azure\"\n",
        "openai.api_version = \"API_DATE\"\n",
        "\n",
        "utterances_ai_reply = []\n",
        "\n",
        "# generate replies\n",
        "msgs = []\n",
        "for utterance_human_idx in tqdm.tqdm(range(2000)):\n",
        "  # try-except as a cheeky way to continue generation if API call does not work\n",
        "  while True:\n",
        "    try:\n",
        "      # 0-shot reply generation\n",
        "      txt = f\"\"\"Generate a reply to this Reddit Post:\n",
        "{utterances_human[int(random.random() * len(utterances_human))]}\n",
        "\"\"\"\n",
        "      # generate\n",
        "      res = openai.chat.completions.create(\n",
        "          model= \"MODEL_NAME\",\n",
        "          messages=[\n",
        "              {\n",
        "                  \"role\": \"user\",\n",
        "                  \"content\": txt\n",
        "              }\n",
        "          ],\n",
        "          temperature=0.4,\n",
        "          max_tokens=256,\n",
        "          presence_penalty=-0.5\n",
        "      )\n",
        "      res = res.choices[0].message.content\n",
        "\n",
        "      # prevent too many posts created that are actually just the AI aplogising\n",
        "      if res == None or \"I'm sorry, but I\" in res:\n",
        "        raise Exception(\"I'm sorry\")\n",
        "\n",
        "      utterances_ai_reply.append(res)\n",
        "      break\n",
        "    except Exception as e:\n",
        "      print(f\"Exception: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "diyWd9VK3iAE"
      },
      "outputs": [],
      "source": [
        "save(utterances_ai_reply, \"ai_reply.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLrJbar-1GoV"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "import random\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "from typing import cast\n",
        "\n",
        "def add_utterance(txt, utterance):\n",
        "  return f\"\"\"\n",
        "  ### START POST ###\n",
        "  {utterances_human[int(random.random() * len(utterances_human))]}\n",
        "  ### END POST ###\n",
        "  \"\"\" + txt\n",
        "\n",
        "client = OpenAI(api_key=\"API_KEY\")\n",
        "utterances_ai_create = []\n",
        "\n",
        "# generate creates\n",
        "for utterance_human_idx in tqdm.tqdm(range(2000)):\n",
        "  # 3-shot creation of a new Reddit Post based on other Reddit Posts\n",
        "  txt = \"\"\"\n",
        "### START POST ###\n",
        "\"\"\"\n",
        "\n",
        "  for i in range(3):\n",
        "    txt = add_utterance(txt, utterances_human[int(random.random() * len(utterances_human))])\n",
        "\n",
        "  # try-except as a cheeky way to continue generation if API call does not work\n",
        "  while True:\n",
        "    try:\n",
        "      # generate\n",
        "      res = client.chat.completions.create(\n",
        "          model= \"gpt-35-turbo-16k\",\n",
        "          messages=[\n",
        "              {\n",
        "                  \"role\": \"user\",\n",
        "                  \"content\": txt\n",
        "              }\n",
        "          ],\n",
        "          temperature=0.6,\n",
        "          max_tokens=256,\n",
        "          presence_penalty=0.5\n",
        "      )\n",
        "      res = res.choices[0].message.content\n",
        "\n",
        "      # prevent too many posts created that are actually just the AI aplogising\n",
        "      if res == None or \"I'm sorry, but I\" in res:\n",
        "        raise Exception()\n",
        "\n",
        "      utterances_ai_create.append(res)\n",
        "      break\n",
        "    except:\n",
        "      continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u57XRGQNssXB"
      },
      "outputs": [],
      "source": [
        "save(utterances_ai_create, \"ai_create.txt\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
